{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy import where\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 2\n",
    "\n",
    "## Useful formula\n",
    "\n",
    "I have written out the folowing formula to help with the work of this worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(X: np.array) -> float:\n",
    "    return - (X * where(X != 0, np.log2(X), 0)).sum()\n",
    "\n",
    "def joint_entropy(D: np.ndarray) -> float:\n",
    "    return - (D * where(D != 0, np.log2(D), 0)).sum()\n",
    "\n",
    "def conditional_entropy(D: np.ndarray, Y: np.array) -> float:\n",
    "    return joint_entropy(D) - entropy(Y)\n",
    "\n",
    "def mutual_information(D: np.ndarray) -> float:\n",
    "    return entropy(D.sum(0)) + entropy(D.sum(1)) - joint_entropy(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: marginal and conditional probabilities\n",
    "\n",
    "Work out the marginal probability distributions and the $x=a$ conditional probability distribution $P(Y\\,|\\,X=a) for:\n",
    "\n",
    "| Y \\ X | a | b |\n",
    "| ---- | ---- | ---- |\n",
    "| 1 | $\\frac{1}{3}$ | $\\frac{1}{6}$ |\n",
    "| 2 | $0$ | $\\frac{1}{4}$ |\n",
    "| 3 | $\\frac{1}{8}$ | $\\frac{1}{8}$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.25      , 0.25      , 0.45833333, 0.54166667])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the distribution\n",
    "\n",
    "D = np.array([\n",
    "    [1/3, 1/6],\n",
    "    [0, 1/4],\n",
    "    [1/8, 1/8]\n",
    "])\n",
    "\n",
    "# Marginal distributions in the order [1,2,3,'a','b']\n",
    "\n",
    "np.concatenate((D.sum(1), D.sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72727273, 0.        , 0.27272727])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditional probability, given X=a\n",
    "\n",
    "given_X = D[:,0]\n",
    "\n",
    "given_X / given_X.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: working out entropy\n",
    "\n",
    "Each throw has a $\\displaystyle\\frac{1}{2}$ chance of being heads, constructing a table:\n",
    "\n",
    "| throws | probability |\n",
    "| ---- | ---- |\n",
    "| 1 | $\\frac{1}{2}$ |\n",
    "| 2 | $\\frac{1}{4}$ |\n",
    "| 3 | $\\frac{1}{8}$ |\n",
    "| 4 | $\\frac{1}{16}$ |\n",
    "| 5 | $\\frac{1}{32}$ |\n",
    "| ... | ... |\n",
    "\n",
    "As you can see from the code below as $\\text{throws} \\rightarrow \\infty$ then $H(X) = 2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:\n",
    "\n",
    "D = np.array([1/2**x for x in range(1, 500)])\n",
    "\n",
    "entropy(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: A puzzle which lends itself to information type reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Working out entropy and information\n",
    "\n",
    "Let $p(x,y)$ be given by $p(0,0)=p(0,1)=p(1,1)=\\displaystyle\\frac{1}{3}$ and $p(1,0)=0$:\n",
    "\n",
    "| Y \\ X | 0 | 1 |\n",
    "| ---- | ---- | ---- |\n",
    "| 0 | $\\frac{1}{3}$ | 0 |\n",
    "| 1 | $\\frac{1}{3}$ | $\\frac{1}{3}$ |\n",
    "\n",
    "Find $H(X), H(Y), H(X\\,|\\,Y), H(Y\\,|\\,X), H(X, Y), H(Y) - H(Y\\,|\\,X)$ and $I(X;Y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the distribution\n",
    "\n",
    "P = np.array([\n",
    "    [1/3, 0],\n",
    "    [1/3, 1/3]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H(X)\n",
    "\n",
    "entropy(P.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9182958340544896"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H(Y)\n",
    "\n",
    "entropy(P.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666665"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H(X|Y)\n",
    "\n",
    "conditional_entropy(P, P.sum(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666665"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H(Y|X)\n",
    "\n",
    "conditional_entropy(P, P.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.584962500721156"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H(X,Y)\n",
    "\n",
    "joint_entropy(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25162916738782304"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H(Y) - H(Y|X)\n",
    "\n",
    "entropy(P.sum(1)) - conditional_entropy(P, P.sum(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: A qeustion about information in the brain\n",
    "\n",
    "The original idea of estimating neural information by binning spike trains was spread across several papers, but one of the main references is ... One aspect of this paper we didn't discuss is the use of extrapolation to estimate the information as the number of samples becomes large based on the behaviour for smaller numbers of samples.\n",
    "\n",
    "Can you give a short, up to five line, summary of what this involves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
